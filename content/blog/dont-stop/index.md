---
title: AGI
date: "2019-05-07"
thumbnail: ./agi_gf.png
description: Artificial general intelligence (AGI) is different from artificial intelligence (AI). Here I try to describe in brief what AGI is and what it aims to achieve.
---
Okay…I know what artificial and intelligence means…but why general?

To answer this question, let’s travel back into the 20th century.

The research in the field of artificial intelligence had begun and it gradually picked up pace with the increasing advancements in technology. Computers could do longer, more tedious calculation faster with each passing year ( unlike me in primary school ) and therefore it was possible to implement the research practically. As more and more algorithms and discoveries filled the quiver of computer scientists, more and more were still formulated until the majority of the scientists thought the pain of getting to create an artificial intelligence too much as compared to the results they were trying to achieve. The research wasn’t altogether abandoned though. Many people found the potential of the algorithms developed during the research to be really high in the field of computing and so, they started using the algorithms individually to solve very specific problems.

For example — the algorithms used in the chess programs to beat humans (deep blue is the most prominent example) are very difficult to create and tough to train as well. They learn more and more with every match and store the information just like our human brain. The problem is that although the algorithm is good for playing chess, it cannot be used to pick up a can of soda using an artificial arm and put it into an artificial mouth.
This brings us to the term ‘narrow-AI’ (used, and most probably coined, by none other than Ray Kurzweil) which basically pertains to the use of artificial intelligence algorithms or concepts to solve very specific problem instead of developing a “brain” that can solve many different kinds of problems like a human does.

* insert Artificial General Intelligence *

Since the beginning of the 21st century, the term artificial intelligence was synonymous to narrow-AI and in some cases, people even used it to define Machine Learning.
In these times of darkness, uncertainty and deep chaos…..there arose some heroes…from the depths of the Land of ComputerSciencita. Nope, bad idea. Let’s get back to normal.
Basically there were some people (no one specific…just some interested people ) related to the field of computer science who were still enthusiastic about developing an actual artificial life form (artificial intelligence) who decided that the term “artificial intelligence” had lost its charm and they cannot use the term without falling to the level of “those machine learning guys” (just kidding..not every AGI enthusiast is a terrible, arrogant person....I mean, c’mon, look at me with your googly eyes! Am I not the perfect role model that you sore people wish to imitate, peasants?!)(just kidding….I love you guys)….
ahem ahem…anyways..

So yeah, in search for a new term, “Artificial General Intelligence” was coined as it represented a general form of intelligence which means a generally intelligent system that is able to do all the general things that a human is able to do generally.

The definition of Artificial General Intelligence on Wikipedia —

_Artificial general intelligence (AGI) is the intelligence of a machine that has the capacity to understand or learn any intellectual task that a human being can. It is a primary goal of some artificial intelligence research and a common topic in science fiction and future studies. Some researchers refer to Artificial general intelligence as “strong AI”, “full AI” or as the ability of a machine to perform “general intelligent action”; others reserve “strong AI” for machines capable of experiencing consciousness._

The reason why the term “strong AI” is not much used is because of two specific reasons ( as informed by Ben Goertzel on Goertzel.org):
<ul>
  <li>Saying that these system are “strong AI” puts the existing AI systems under the term “weak AI” (since the antonym of strong is weak) which is insulting to the systems’ creators.</li>
  <li>_(the text is copied as is from Goertzel.org)_ 
    Secondly, “strong AI” has a specific meaning in the philosophy of AI — it refers to John Searle’s hypothesis that, if an intelligent system behaves as if it has a mind, then we should assume it actually has a mind.</li>
</ul>

According to Ben Goertzel, Shane Legg who is an AI researcher came up with the term when Ben mailed his friends asking for suggestions for his upcoming book which was then titled AGI.

There it is. A brief introduction of AGI. Ultimately, it is the pure AI that sci-fi movies have made us dream but because of the change in definition of the term, a new term had to be coined.

You can visit Goertzel.org for further reading about AGI or check out his book co-authored with Cassio Pennachin.
